{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649a88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e737f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"marktplc_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1985ad91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>portal</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>listing_price_eur_fixed</th>\n",
       "      <th>status</th>\n",
       "      <th>sale_time</th>\n",
       "      <th>gmv_eur_fixed</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand_is_verified</th>\n",
       "      <th>...</th>\n",
       "      <th>first_listing_local_date</th>\n",
       "      <th>listing_platform</th>\n",
       "      <th>registration_platform</th>\n",
       "      <th>registration_local_date</th>\n",
       "      <th>total_positive_feedback_count</th>\n",
       "      <th>total_negative_feedback_count</th>\n",
       "      <th>window_items_listed</th>\n",
       "      <th>window_items_bought</th>\n",
       "      <th>window_items_sold</th>\n",
       "      <th>listings_in_first_7days_detailed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr</td>\n",
       "      <td>1327185072</td>\n",
       "      <td>2019-08-13 10:12:04</td>\n",
       "      <td>110132322</td>\n",
       "      <td>20.0</td>\n",
       "      <td>d. Very good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-02-20</td>\n",
       "      <td>iphone</td>\n",
       "      <td>iphone</td>\n",
       "      <td>2019-02-20</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>c. 2-5 listings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr</td>\n",
       "      <td>1435162762</td>\n",
       "      <td>2019-08-07 09:35:10</td>\n",
       "      <td>100878662</td>\n",
       "      <td>2.5</td>\n",
       "      <td>c. Mint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jbc</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>iphone</td>\n",
       "      <td>iphone</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>688</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>h. 101-500 listings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr</td>\n",
       "      <td>1223939862</td>\n",
       "      <td>2019-08-10 14:16:24</td>\n",
       "      <td>100278072</td>\n",
       "      <td>10.0</td>\n",
       "      <td>c. Mint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pour moi</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>android</td>\n",
       "      <td>android</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>e. 11-20 listings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr</td>\n",
       "      <td>1015951762</td>\n",
       "      <td>2019-08-06 21:57:17</td>\n",
       "      <td>120649022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>c. Mint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bebe confort</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>iphone</td>\n",
       "      <td>iphone</td>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d. 6-10 listings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr</td>\n",
       "      <td>1052026072</td>\n",
       "      <td>2019-08-13 11:17:25</td>\n",
       "      <td>120062171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c. Mint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kimbaloo</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>android</td>\n",
       "      <td>iphone</td>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>a. Didn't list over first 7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fr</td>\n",
       "      <td>1159724972</td>\n",
       "      <td>2019-08-26 18:10:03</td>\n",
       "      <td>110688831</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b. New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>android</td>\n",
       "      <td>android</td>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>a. Didn't list over first 7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fr</td>\n",
       "      <td>1621402182</td>\n",
       "      <td>2019-08-29 13:40:54</td>\n",
       "      <td>120051541</td>\n",
       "      <td>2.0</td>\n",
       "      <td>c. Mint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jennyfer</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>iphone</td>\n",
       "      <td>iphone</td>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d. 6-10 listings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fr</td>\n",
       "      <td>1474625082</td>\n",
       "      <td>2019-08-28 13:51:55</td>\n",
       "      <td>120415481</td>\n",
       "      <td>18.0</td>\n",
       "      <td>a. New with tags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chanel</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-11-11</td>\n",
       "      <td>iphone</td>\n",
       "      <td>iphone</td>\n",
       "      <td>2018-09-09</td>\n",
       "      <td>119</td>\n",
       "      <td>7</td>\n",
       "      <td>306</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>a. Didn't list over first 7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fr</td>\n",
       "      <td>1101201282</td>\n",
       "      <td>2019-08-30 18:00:37</td>\n",
       "      <td>120613962</td>\n",
       "      <td>5.0</td>\n",
       "      <td>c. Mint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La Redoute</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>web (desktop or other)</td>\n",
       "      <td>web (desktop or other)</td>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>e. 11-20 listings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fr</td>\n",
       "      <td>1517800182</td>\n",
       "      <td>2019-08-29 09:37:27</td>\n",
       "      <td>110235241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c. Mint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pony</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-06</td>\n",
       "      <td>android</td>\n",
       "      <td>android</td>\n",
       "      <td>2017-10-19</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>a. Didn't list over first 7d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  portal          id           created_at    user_id  listing_price_eur_fixed  \\\n",
       "0     fr  1327185072  2019-08-13 10:12:04  110132322                     20.0   \n",
       "1     fr  1435162762  2019-08-07 09:35:10  100878662                      2.5   \n",
       "2     fr  1223939862  2019-08-10 14:16:24  100278072                     10.0   \n",
       "3     fr  1015951762  2019-08-06 21:57:17  120649022                     20.0   \n",
       "4     fr  1052026072  2019-08-13 11:17:25  120062171                      1.0   \n",
       "5     fr  1159724972  2019-08-26 18:10:03  110688831                      5.0   \n",
       "6     fr  1621402182  2019-08-29 13:40:54  120051541                      2.0   \n",
       "7     fr  1474625082  2019-08-28 13:51:55  120415481                     18.0   \n",
       "8     fr  1101201282  2019-08-30 18:00:37  120613962                      5.0   \n",
       "9     fr  1517800182  2019-08-29 09:37:27  110235241                      1.0   \n",
       "\n",
       "             status sale_time  gmv_eur_fixed         brand  brand_is_verified  \\\n",
       "0      d. Very good       NaN            NaN           NaN              False   \n",
       "1           c. Mint       NaN            NaN           jbc               True   \n",
       "2           c. Mint       NaN            NaN      Pour moi               True   \n",
       "3           c. Mint       NaN            NaN  Bebe confort              False   \n",
       "4           c. Mint       NaN            NaN      Kimbaloo               True   \n",
       "5            b. New       NaN            NaN           NaN              False   \n",
       "6           c. Mint       NaN            NaN      Jennyfer               True   \n",
       "7  a. New with tags       NaN            NaN        Chanel               True   \n",
       "8           c. Mint       NaN            NaN    La Redoute               True   \n",
       "9           c. Mint       NaN            NaN          Pony               True   \n",
       "\n",
       "   ... first_listing_local_date        listing_platform  \\\n",
       "0  ...               2019-02-20                  iphone   \n",
       "1  ...               2019-07-24                  iphone   \n",
       "2  ...               2019-08-10                 android   \n",
       "3  ...               2019-02-13                  iphone   \n",
       "4  ...               2019-06-06                 android   \n",
       "5  ...               2019-08-08                 android   \n",
       "6  ...               2017-11-09                  iphone   \n",
       "7  ...               2018-11-11                  iphone   \n",
       "8  ...               2019-08-04  web (desktop or other)   \n",
       "9  ...               2018-09-06                 android   \n",
       "\n",
       "    registration_platform  registration_local_date  \\\n",
       "0                  iphone               2019-02-20   \n",
       "1                  iphone               2019-07-24   \n",
       "2                 android               2019-08-10   \n",
       "3                  iphone               2019-02-13   \n",
       "4                  iphone               2018-05-21   \n",
       "5                 android               2017-09-21   \n",
       "6                  iphone               2017-11-09   \n",
       "7                  iphone               2018-09-09   \n",
       "8  web (desktop or other)               2019-08-04   \n",
       "9                 android               2017-10-19   \n",
       "\n",
       "  total_positive_feedback_count total_negative_feedback_count  \\\n",
       "0                             7                             0   \n",
       "1                            11                             0   \n",
       "2                             0                             0   \n",
       "3                             4                             0   \n",
       "4                            14                             0   \n",
       "5                            11                             0   \n",
       "6                             3                             3   \n",
       "7                           119                             7   \n",
       "8                             9                             0   \n",
       "9                            35                             0   \n",
       "\n",
       "  window_items_listed window_items_bought window_items_sold  \\\n",
       "0                  96                   1                 7   \n",
       "1                 688                   7                22   \n",
       "2                   0                   0                 0   \n",
       "3                   0                   0                 0   \n",
       "4                 168                  10                21   \n",
       "5                  21                   4                 6   \n",
       "6                   0                   0                 0   \n",
       "7                 306                  18                48   \n",
       "8                  28                   9                 4   \n",
       "9                  32                   1                 8   \n",
       "\n",
       "  listings_in_first_7days_detailed  \n",
       "0                  c. 2-5 listings  \n",
       "1              h. 101-500 listings  \n",
       "2                e. 11-20 listings  \n",
       "3                 d. 6-10 listings  \n",
       "4     a. Didn't list over first 7d  \n",
       "5     a. Didn't list over first 7d  \n",
       "6                 d. 6-10 listings  \n",
       "7     a. Didn't list over first 7d  \n",
       "8                e. 11-20 listings  \n",
       "9     a. Didn't list over first 7d  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75611c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['portal', 'id', 'created_at', 'user_id', 'listing_price_eur_fixed',\n",
       "       'status', 'sale_time', 'gmv_eur_fixed', 'brand', 'brand_is_verified',\n",
       "       'declined_at', 'color_primary', 'listing_quality_string',\n",
       "       'suggested_price_maximum', 'catalog_code_1', 'catalog_code_2',\n",
       "       'catalog_code_3', 'catalog_code_4', 'catalog_code_5', 'gender',\n",
       "       'country_code', 'lister_nth_listing', 'first_listing_local_date',\n",
       "       'listing_platform', 'registration_platform', 'registration_local_date',\n",
       "       'total_positive_feedback_count', 'total_negative_feedback_count',\n",
       "       'window_items_listed', 'window_items_bought', 'window_items_sold',\n",
       "       'listings_in_first_7days_detailed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06009097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "declined_at                         97.309346\n",
       "catalog_code_5                      95.283790\n",
       "sale_time                           71.058420\n",
       "gmv_eur_fixed                       71.058420\n",
       "listing_quality_string              48.610183\n",
       "suggested_price_maximum             25.165766\n",
       "brand                               21.666155\n",
       "catalog_code_4                      19.694349\n",
       "color_primary                        6.852427\n",
       "gender                               5.532169\n",
       "catalog_code_3                       1.052639\n",
       "lister_nth_listing                   0.000000\n",
       "total_positive_feedback_count        0.000000\n",
       "total_negative_feedback_count        0.000000\n",
       "registration_local_date              0.000000\n",
       "registration_platform                0.000000\n",
       "listing_platform                     0.000000\n",
       "window_items_listed                  0.000000\n",
       "window_items_bought                  0.000000\n",
       "window_items_sold                    0.000000\n",
       "first_listing_local_date             0.000000\n",
       "portal                               0.000000\n",
       "country_code                         0.000000\n",
       "id                                   0.000000\n",
       "catalog_code_2                       0.000000\n",
       "catalog_code_1                       0.000000\n",
       "brand_is_verified                    0.000000\n",
       "status                               0.000000\n",
       "listing_price_eur_fixed              0.000000\n",
       "user_id                              0.000000\n",
       "created_at                           0.000000\n",
       "listings_in_first_7days_detailed     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_values = data.isnull().mean() * 100\n",
    "\n",
    "# Sort missing values in descending order for better understanding\n",
    "missing_values_sorted = missing_values.sort_values(ascending=False)\n",
    "missing_values_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5ffb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with very high missing values\n",
    "data_cleaned = data.drop(columns=['declined_at', 'catalog_code_5','portal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04093c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing categorical data with \"Unknown\"\n",
    "categorical_columns = ['brand', 'color_primary', 'gender', 'listing_quality_string']\n",
    "data_cleaned[categorical_columns] = data_cleaned[categorical_columns].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22595b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing numerical data\n",
    "# Fill 'suggested_price_maximum' with the median value\n",
    "data_cleaned['suggested_price_maximum'] = data_cleaned['suggested_price_maximum'].fillna(\n",
    "    data_cleaned['suggested_price_maximum'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "688bd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill 'gmv_eur_fixed' with 0 (assuming missing values mean no sale)\n",
    "data_cleaned['gmv_eur_fixed'] = data_cleaned['gmv_eur_fixed'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "025604cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sale_time                           71.058420\n",
       "catalog_code_4                      19.694349\n",
       "catalog_code_3                       1.052639\n",
       "window_items_sold                    0.000000\n",
       "window_items_bought                  0.000000\n",
       "window_items_listed                  0.000000\n",
       "total_negative_feedback_count        0.000000\n",
       "total_positive_feedback_count        0.000000\n",
       "registration_local_date              0.000000\n",
       "registration_platform                0.000000\n",
       "listing_platform                     0.000000\n",
       "first_listing_local_date             0.000000\n",
       "lister_nth_listing                   0.000000\n",
       "country_code                         0.000000\n",
       "gender                               0.000000\n",
       "id                                   0.000000\n",
       "created_at                           0.000000\n",
       "catalog_code_2                       0.000000\n",
       "catalog_code_1                       0.000000\n",
       "suggested_price_maximum              0.000000\n",
       "listing_quality_string               0.000000\n",
       "color_primary                        0.000000\n",
       "brand_is_verified                    0.000000\n",
       "brand                                0.000000\n",
       "gmv_eur_fixed                        0.000000\n",
       "status                               0.000000\n",
       "listing_price_eur_fixed              0.000000\n",
       "user_id                              0.000000\n",
       "listings_in_first_7days_detailed     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the missing values after cleaning\n",
    "missing_values_after_cleaning = data_cleaned.isnull().mean() * 100\n",
    "\n",
    "missing_values_after_cleaning.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490a1c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2019-02-20\n",
       "1   2019-07-24\n",
       "2   2019-08-10\n",
       "3   2019-02-13\n",
       "4   2018-05-21\n",
       "5   2017-09-21\n",
       "6   2017-11-09\n",
       "7   2018-09-09\n",
       "8   2019-08-04\n",
       "9   2017-10-19\n",
       "Name: registration_local_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date columns to datetime format for easier processing\n",
    "data_cleaned['created_at'] = pd.to_datetime(data_cleaned['created_at'])\n",
    "#data_cleaned['sale_time'] = pd.to_datetime(data_cleaned['sale_time'], errors='coerce')  # Coerce errors for NaT values\n",
    "data_cleaned['first_listing_local_date'] = pd.to_datetime(data_cleaned['first_listing_local_date'])\n",
    "data_cleaned['registration_local_date'] = pd.to_datetime(data_cleaned['registration_local_date'])\n",
    "data_cleaned['registration_local_date'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d098fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sold\n",
       "0    314641\n",
       "1    128151\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature 1: Time to sell (difference between created_at and sale_time)\n",
    "#data_cleaned['time_to_sell'] = (data_cleaned['sale_time'] - data_cleaned['created_at']).dt.days\n",
    "\n",
    "# Create a new target variable 'sold'\n",
    "data_cleaned['sold'] = data_cleaned['sale_time'].notna().astype(int)\n",
    "data_cleaned['sold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85db057e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3511      1919\n",
       "309146    1919\n",
       "113488    1919\n",
       "146408    1919\n",
       "411572    1919\n",
       "          ... \n",
       "148793    1950\n",
       "343645    1950\n",
       "302451    1950\n",
       "269802    1950\n",
       "203543    1950\n",
       "Name: listing_age, Length: 442792, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature 2: Age of the listing (difference between today and created_at)\n",
    "data_cleaned['listing_age'] = (pd.Timestamp.now() - data_cleaned['created_at']).dt.days\n",
    "data_cleaned['listing_age'].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f942ee0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28461     4272\n",
       "308587    4272\n",
       "244575    4272\n",
       "75626     4268\n",
       "288516    4268\n",
       "          ... \n",
       "291292    1920\n",
       "406928    1920\n",
       "238487    1920\n",
       "382772    1920\n",
       "252095    1920\n",
       "Name: user_account_age, Length: 442792, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature 3: User account age (difference between today and registration date)\n",
    "data_cleaned['user_account_age'] = (pd.Timestamp.now() - data_cleaned['registration_local_date']).dt.days\n",
    "data_cleaned['user_account_age'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c616c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the new features\n",
    "#data_cleaned[['time_to_sell', 'listing_age', 'user_account_age']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58afa37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive_feedback_ratio\n",
       "1.000000    208099\n",
       "0.000000     97932\n",
       "0.857143      1672\n",
       "0.916667      1538\n",
       "0.923077      1536\n",
       "             ...  \n",
       "0.998665         1\n",
       "0.994987         1\n",
       "0.962222         1\n",
       "0.996583         1\n",
       "0.978693         1\n",
       "Name: count, Length: 3206, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add behavioral features\n",
    "\n",
    "# Positive feedback ratio\n",
    "data_cleaned['positive_feedback_ratio'] = data_cleaned['total_positive_feedback_count'] / (\n",
    "    data_cleaned['total_positive_feedback_count'] + data_cleaned['total_negative_feedback_count']\n",
    ")\n",
    "data_cleaned['positive_feedback_ratio'] = data_cleaned['positive_feedback_ratio'].fillna(0)  # Handle NaN\n",
    "data_cleaned['positive_feedback_ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e32eaaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative_feedback_ratio\n",
       "0.000000    304682\n",
       "0.142857      1672\n",
       "0.083333      1538\n",
       "0.076923      1536\n",
       "0.058824      1508\n",
       "             ...  \n",
       "0.001335         1\n",
       "0.005013         1\n",
       "0.037778         1\n",
       "0.003417         1\n",
       "0.021307         1\n",
       "Name: count, Length: 3206, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative feedback ratio\n",
    "data_cleaned['negative_feedback_ratio'] = data_cleaned['total_negative_feedback_count'] / (\n",
    "    data_cleaned['total_positive_feedback_count'] + data_cleaned['total_negative_feedback_count']\n",
    ")\n",
    "data_cleaned['negative_feedback_ratio'] = data_cleaned['negative_feedback_ratio'].fillna(0)  # Handle NaN\n",
    "data_cleaned['negative_feedback_ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d8b44ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales_success_ratio\n",
       "0.000000    120899\n",
       "0.500000      7970\n",
       "0.333333      7550\n",
       "1.000000      7000\n",
       "0.250000      6522\n",
       "             ...  \n",
       "0.145278         1\n",
       "0.077821         1\n",
       "0.145540         1\n",
       "0.561798         1\n",
       "4.666667         1\n",
       "Name: count, Length: 8930, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sales success ratio\n",
    "data_cleaned['sales_success_ratio'] = data_cleaned['window_items_sold'] / data_cleaned['window_items_listed']\n",
    "data_cleaned['sales_success_ratio'] = data_cleaned['sales_success_ratio'].fillna(0)  # Handle NaN\n",
    "\n",
    "# Replace infinite values in the 'sales_success_ratio' column with NaN\n",
    "data_cleaned['sales_success_ratio'].replace([float('inf'), float('-inf')], float('nan'), inplace=True)\n",
    "# Fill NaN values with 0\n",
    "data_cleaned['sales_success_ratio'].fillna(0, inplace=True) \n",
    "\n",
    "data_cleaned['sales_success_ratio'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0727f4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive_feedback_ratio</th>\n",
       "      <th>negative_feedback_ratio</th>\n",
       "      <th>sales_success_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.156863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positive_feedback_ratio  negative_feedback_ratio  sales_success_ratio\n",
       "0                 1.000000                 0.000000             0.072917\n",
       "1                 1.000000                 0.000000             0.031977\n",
       "2                 0.000000                 0.000000             0.000000\n",
       "3                 1.000000                 0.000000             0.000000\n",
       "4                 1.000000                 0.000000             0.125000\n",
       "5                 1.000000                 0.000000             0.285714\n",
       "6                 0.500000                 0.500000             0.000000\n",
       "7                 0.944444                 0.055556             0.156863\n",
       "8                 1.000000                 0.000000             0.142857\n",
       "9                 1.000000                 0.000000             0.250000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the new features\n",
    "data_cleaned[['positive_feedback_ratio', 'negative_feedback_ratio', 'sales_success_ratio']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdfd28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "nominal_columns = ['country_code', 'color_primary']\n",
    "ordinal_columns = ['listing_quality_string']\n",
    "\n",
    "# Apply Label Encoding to nominal columns\n",
    "for col in nominal_columns:\n",
    "    data_cleaned[col] = label_encoder.fit_transform(data_cleaned[col])\n",
    "\n",
    "# Also want to apply Label Encoding to the ordinal columns (if they are categorical),\n",
    "# We can do the same for those columns as well (optional, depending on the data).\n",
    "\n",
    "for col in ordinal_columns:\n",
    "    data_cleaned[col] = label_encoder.fit_transform(data_cleaned[col])\n",
    "\n",
    "# Now the data is encoded with Label Encoding for both nominal and ordinal columns.\n",
    "\n",
    "# We can also encode the 'brand' column, but if there are many categories we can only select the most important brands\n",
    "# If there is a lot of unique value, it is useful to select only the most common brands and separate the rest as 'other'.\n",
    "top_brands = data_cleaned['brand'].value_counts().nlargest(10).index  # The 10 most common brands\n",
    "data_cleaned['brand'] = data['brand'].apply(lambda x: x if x in top_brands else 'other')\n",
    "data_cleaned = pd.get_dummies(data_cleaned, columns=['brand'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf07184a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color_primary\n",
       "1     102637\n",
       "2      46729\n",
       "11     42547\n",
       "27     38724\n",
       "25     30342\n",
       "19     20685\n",
       "21     20628\n",
       "4      18020\n",
       "26     17373\n",
       "3      16515\n",
       "17     14569\n",
       "22      9806\n",
       "28      7679\n",
       "10      7361\n",
       "12      6577\n",
       "20      5558\n",
       "13      5530\n",
       "5       4767\n",
       "7       4462\n",
       "18      4338\n",
       "9       3744\n",
       "23      3641\n",
       "24      2960\n",
       "6       2380\n",
       "16      1737\n",
       "8        987\n",
       "14       953\n",
       "15       870\n",
       "0        673\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned[\"color_primary\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d259cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status_mapped\n",
       "2    252905\n",
       "1     73251\n",
       "3     68423\n",
       "0     40166\n",
       "4      8047\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the mapping for 'status' column to numerical values\n",
    "status_mapping = {\n",
    "    'a. New with tags': 0,\n",
    "    'b. New': 1,\n",
    "    'c. Mint': 2,\n",
    "    'd. Very good': 3,\n",
    "    'e. Good': 4\n",
    "}\n",
    "\n",
    "# Map the 'status' column to 'status_mapped' column with the defined mapping\n",
    "data_cleaned['status_mapped'] = data_cleaned['status'].map(status_mapping)\n",
    "\n",
    "# Drop the 'status' column from the dataset as it is no longer needed\n",
    "data_cleaned = data_cleaned.drop(columns=['status'])\n",
    "data_cleaned[\"status_mapped\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e695b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non-numeric columns in the dataset\n",
    "non_numeric_columns = data_cleaned.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Apply Label Encoding to each non-numeric column in data_cleaned\n",
    "for col in non_numeric_columns:\n",
    "    data_cleaned[col] = label_encoder.fit_transform(data_cleaned[col])  # Fit and transform on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8e7d3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country_code\n",
       "FR    384728\n",
       "BE     39019\n",
       "ES     19045\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"country_code\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12f77165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for datetime columns\n",
    "datetime_columns = data_cleaned.select_dtypes(include=['datetime']).columns\n",
    "\n",
    "# Convert datetime columns to numeric values (e.g., Unix timestamp or individual components)\n",
    "for col in datetime_columns:\n",
    "    # Convert to Unix timestamp (seconds since 1970-01-01)\n",
    "    data_cleaned[col] = data_cleaned[col].astype('int64') // 10**9  # Converting to seconds\n",
    "\n",
    "    # Or, alternatively, could extract individual components like year, month, day\n",
    "    # data_cleaned[f'{col}_year'] = data_cleaned[col].dt.year\n",
    "    # data_cleaned[f'{col}_month'] = data_cleaned[col].dt.month\n",
    "    # data_cleaned[f'{col}_day'] = data_cleaned[col].dt.day\n",
    "    # data_cleaned = data_cleaned.drop(columns=[col])  # Drop original datetime column if needed\n",
    "\n",
    "# Now proceed with encoding the categorical columns as before and fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74b0cc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sold                                1.000000\n",
      "gmv_eur_fixed                       0.251380\n",
      "window_items_sold                   0.115595\n",
      "total_positive_feedback_count       0.101739\n",
      "sales_success_ratio                 0.089173\n",
      "positive_feedback_ratio             0.088679\n",
      "window_items_bought                 0.087251\n",
      "suggested_price_maximum             0.079221\n",
      "brand_is_verified                   0.073019\n",
      "total_negative_feedback_count       0.070351\n",
      "user_account_age                    0.057828\n",
      "country_code                        0.051880\n",
      "brand_Nike                          0.051319\n",
      "lister_nth_listing                  0.027079\n",
      "registration_platform               0.026536\n",
      "brand_Zara                          0.019862\n",
      "brand_Disney                        0.017450\n",
      "brand_Tape à l’œil                  0.016438\n",
      "color_primary                       0.014993\n",
      "listing_age                         0.014325\n",
      "window_items_listed                 0.012721\n",
      "negative_feedback_ratio             0.007921\n",
      "listing_price_eur_fixed             0.002605\n",
      "listing_platform                    0.001225\n",
      "id                                  0.001112\n",
      "catalog_code_4                      0.000774\n",
      "brand_Kiabi                        -0.001360\n",
      "brand_ORCHESTRA                    -0.011828\n",
      "created_at                         -0.014877\n",
      "listings_in_first_7days_detailed   -0.014881\n",
      "catalog_code_3                     -0.015980\n",
      "brand_H&M                          -0.022226\n",
      "brand_Pimkie                       -0.027458\n",
      "brand_other                        -0.027977\n",
      "user_id                            -0.028031\n",
      "gender                             -0.041063\n",
      "catalog_code_1                     -0.046598\n",
      "catalog_code_2                     -0.052305\n",
      "listing_quality_string             -0.056762\n",
      "registration_local_date            -0.058265\n",
      "first_listing_local_date           -0.059753\n",
      "status_mapped                      -0.069377\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data_cleaned = data_cleaned.drop(columns=\"sale_time\")\n",
    "correlations = data_cleaned.corrwith(data_cleaned['sold'])\n",
    "correlations_sorted = correlations.sort_values(ascending=False)\n",
    "print(correlations_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b2d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Cross-validation scores: [0.62179062 0.62275043 0.62373848 0.61716964 0.62270276]\n",
      "Mean CV score: 0.6216303862475455\n",
      "Logistic Regression Performance Metrics:\n",
      "Accuracy: 0.6188\n",
      "Precision: 0.3933\n",
      "Recall: 0.5847\n",
      "F1 Score: 0.4703\n",
      "F2 Score: 0.5328\n",
      "Confusion Matrix:\n",
      "[[39812 23117]\n",
      " [10645 14985]]\n",
      "\n",
      "Training Decision Tree...\n",
      "Cross-validation scores: [0.60884723 0.6131664  0.61910878 0.62895576 0.64106654]\n",
      "Mean CV score: 0.6222289441255152\n",
      "Decision Tree Performance Metrics:\n",
      "Accuracy: 0.6183\n",
      "Precision: 0.3970\n",
      "Recall: 0.6148\n",
      "F1 Score: 0.4825\n",
      "F2 Score: 0.5540\n",
      "Confusion Matrix:\n",
      "[[38996 23933]\n",
      " [ 9873 15757]]\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "Cross-validation scores: [0.70690361 0.70889381 0.70508278 0.70780284 0.70788753]\n",
      "Mean CV score: 0.7073141154611223\n",
      "K-Nearest Neighbors Performance Metrics:\n",
      "Accuracy: 0.7119\n",
      "Precision: 0.5041\n",
      "Recall: 0.2838\n",
      "F1 Score: 0.3632\n",
      "F2 Score: 0.3110\n",
      "Confusion Matrix:\n",
      "[[55773  7156]\n",
      " [18356  7274]]\n",
      "\n",
      "Training AdaBoost...\n",
      "Cross-validation scores: [0.71374935 0.71462447 0.7142716  0.71471925 0.71456398]\n",
      "Mean CV score: 0.7143857306116959\n",
      "AdaBoost Performance Metrics:\n",
      "Accuracy: 0.7143\n",
      "Precision: 0.6279\n",
      "Recall: 0.0314\n",
      "F1 Score: 0.0598\n",
      "F2 Score: 0.0388\n",
      "Confusion Matrix:\n",
      "[[62452   477]\n",
      " [24825   805]]\n",
      "\n",
      "Training XGBoost...\n",
      "Cross-validation scores: [0.32712747 0.32567363 0.32333056 0.32494425 0.32446433]\n",
      "Mean CV score: 0.3251080480714112\n",
      "XGBoost Performance Metrics:\n",
      "Accuracy: 0.3254\n",
      "Precision: 0.2994\n",
      "Recall: 0.9934\n",
      "F1 Score: 0.4602\n",
      "F2 Score: 0.6788\n",
      "Confusion Matrix:\n",
      "[[ 3358 59571]\n",
      " [  168 25462]]\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Cross-validation scores: [0.73624854 0.74001722 0.73788587 0.73624481 0.73719053]\n",
      "Mean CV score: 0.737517392226456\n",
      "Gradient Boosting Performance Metrics:\n",
      "Accuracy: 0.7380\n",
      "Precision: 0.6531\n",
      "Recall: 0.2019\n",
      "F1 Score: 0.3084\n",
      "F2 Score: 0.2342\n",
      "Confusion Matrix:\n",
      "[[60181  2748]\n",
      " [20456  5174]]\n",
      "\n",
      "Training Random Forest...\n",
      "Cross-validation scores: [0.64300535 0.644191   0.6443745  0.64007848 0.64604918]\n",
      "Mean CV score: 0.6435397014062901\n",
      "Random Forest Performance Metrics:\n",
      "Accuracy: 0.6431\n",
      "Precision: 0.4217\n",
      "Recall: 0.6282\n",
      "F1 Score: 0.5047\n",
      "F2 Score: 0.5722\n",
      "Confusion Matrix:\n",
      "[[40851 22078]\n",
      " [ 9528 16102]]\n",
      "\n",
      "Training LinearSVC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.61766906 0.61915113 0.61951812 0.61393727 0.61889168]\n",
      "Mean CV score: 0.6178334518863268\n",
      "LinearSVC Performance Metrics:\n",
      "Accuracy: 0.6154\n",
      "Precision: 0.3902\n",
      "Recall: 0.5843\n",
      "F1 Score: 0.4679\n",
      "F2 Score: 0.5314\n",
      "Confusion Matrix:\n",
      "[[39524 23405]\n",
      " [10655 14975]]\n",
      "\n",
      "Training Support Vector Machine (Linear Kernel)...\n"
     ]
    }
   ],
   "source": [
    "# Define target variable (assuming 'sold' is the binary target: sold=1, not sold=0)\n",
    "target = 'sold'\n",
    "features_to_exclude = ['gmv_eur_fixed']\n",
    "X = data_cleaned.drop(columns=features_to_exclude + [target])\n",
    "y = data_cleaned[target]\n",
    "\n",
    "# Feature selection: Select the top 20 features\n",
    "selector = SelectKBest(f_classif, k=20)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Split the data into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply scaling to the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model list\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=0.1, penalty='l2', random_state=42, class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=7, min_samples_split=5, min_samples_leaf=2, random_state=42, class_weight='balanced'),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=7, weights='uniform', algorithm='auto'),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=150, learning_rate=0.05, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, max_depth=7, learning_rate=0.05, scale_pos_weight=10, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=150, max_depth=7, learning_rate=0.05, random_state=42, subsample=0.9),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, min_samples_leaf=2, max_features='sqrt', random_state=42, class_weight='balanced'),\n",
    "    \"LinearSVC\": LinearSVC(max_iter=10000, random_state=42, class_weight='balanced', C=0.5),\n",
    "    \"Support Vector Machine (Linear Kernel)\": SVC(kernel='linear', C=0.5, random_state=42, class_weight='balanced')\n",
    "    \n",
    "}\n",
    "\n",
    "# A dictionary to train all models and keep the evaluation results\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "\n",
    "    # Fit the model on the training set\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculating performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "\n",
    "    results[model_name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"F2 Score\": f2\n",
    "    }\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)  # 5-fold cross-validation\n",
    "    print(f\"Cross-validation scores: {cv_scores}\")\n",
    "    print(f\"Mean CV score: {cv_scores.mean()}\")\n",
    "\n",
    "    # Printing performance metrics\n",
    "    print(f\"{model_name} Performance Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"F2 Score: {f2:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "# Show results as a DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34eebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define target variable (assuming 'sold' is the binary target: sold=1, not sold=0)\n",
    "# target = 'sold'\n",
    "# features_to_exclude = ['gmv_eur_fixed']\n",
    "# X = data_cleaned.drop(columns=features_to_exclude + [target])\n",
    "# y = data_cleaned[target]\n",
    "\n",
    "# # Feature selection: Select the top 20 features\n",
    "# selector = SelectKBest(f_classif, k=20)\n",
    "# X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# # Split the data into training and test sets (80-20 split)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# # Apply scaling to the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # K-Nearest Neighbors Model\n",
    "# knn_model = KNeighborsClassifier(n_neighbors=5)  # Default n_neighbors=5\n",
    "# print(\"\\nTraining K-Nearest Neighbors...\")\n",
    "\n",
    "# # Fit the model on the training set\n",
    "# knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# # Calculating performance metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "\n",
    "# # Cross-validation scores\n",
    "# cv_scores = cross_val_score(knn_model, X_train_scaled, y_train, cv=5)  # 5-fold cross-validation\n",
    "# print(f\"Cross-validation scores: {cv_scores}\")\n",
    "# print(f\"Mean CV score: {cv_scores.mean()}\")\n",
    "\n",
    "# # Printing performance metrics\n",
    "# print(\"\\nK-Nearest Neighbors Performance Metrics:\")\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1 Score: {f1:.4f}\")\n",
    "# print(f\"F2 Score: {f2:.4f}\")\n",
    "\n",
    "# # Confusion Matrix\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93762716",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"marktplc_testing.csv\")\n",
    "print(test_data.info())\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_values = test_data.isnull().mean() * 100\n",
    "\n",
    "# Sort missing values in descending order for better understanding\n",
    "missing_values_sorted = missing_values.sort_values(ascending=False)\n",
    "missing_values_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with very high missing values\n",
    "test_data_cleaned = test_data.drop(columns=['declined_at', 'catalog_code_5','portal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d05c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing categorical data with \"Unknown\"\n",
    "categorical_columns = ['brand', 'color_primary', 'gender', 'listing_quality_string']\n",
    "test_data_cleaned[categorical_columns] = test_data_cleaned[categorical_columns].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafa7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing numerical data\n",
    "# Fill 'suggested_price_maximum' with the median value\n",
    "test_data_cleaned['suggested_price_maximum'] = test_data_cleaned['suggested_price_maximum'].fillna(\n",
    "    test_data_cleaned['suggested_price_maximum'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c857cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_values = test_data_cleaned.isnull().mean() * 100\n",
    "\n",
    "# Sort missing values in descending order for better understanding\n",
    "missing_values_sorted = missing_values.sort_values(ascending=False)\n",
    "missing_values_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format for easier processing\n",
    "test_data_cleaned['created_at'] = pd.to_datetime(test_data_cleaned['created_at'])\n",
    "#test_data_cleaned['sale_time'] = pd.to_datetime(test_data_cleaned['sale_time'], errors='coerce')  # Coerce errors for NaT values\n",
    "test_data_cleaned['first_listing_local_date'] = pd.to_datetime(test_data_cleaned['first_listing_local_date'])\n",
    "test_data_cleaned['registration_local_date'] = pd.to_datetime(test_data_cleaned['registration_local_date'])\n",
    "test_data_cleaned['registration_local_date'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a61788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 2: Age of the listing (difference between today and created_at)\n",
    "test_data_cleaned['listing_age'] = (pd.Timestamp.now() - test_data_cleaned['created_at']).dt.days\n",
    "test_data_cleaned['listing_age'].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d609a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3: User account age (difference between today and registration date)\n",
    "test_data_cleaned['user_account_age'] = (pd.Timestamp.now() - test_data_cleaned['registration_local_date']).dt.days\n",
    "test_data_cleaned['user_account_age'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a55158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add behavioral features\n",
    "\n",
    "# Positive feedback ratio\n",
    "test_data_cleaned['positive_feedback_ratio'] = test_data_cleaned['total_positive_feedback_count'] / (\n",
    "    test_data_cleaned['total_positive_feedback_count'] + test_data_cleaned['total_negative_feedback_count']\n",
    ")\n",
    "test_data_cleaned['positive_feedback_ratio'] = test_data_cleaned['positive_feedback_ratio'].fillna(0)  # Handle NaN\n",
    "test_data_cleaned['positive_feedback_ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative feedback ratio\n",
    "test_data_cleaned['negative_feedback_ratio'] = test_data_cleaned['total_negative_feedback_count'] / (\n",
    "    test_data_cleaned['total_positive_feedback_count'] + test_data_cleaned['total_negative_feedback_count']\n",
    ")\n",
    "test_data_cleaned['negative_feedback_ratio'] = test_data_cleaned['negative_feedback_ratio'].fillna(0)  # Handle NaN\n",
    "test_data_cleaned['negative_feedback_ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales success ratio\n",
    "test_data_cleaned['sales_success_ratio'] = test_data_cleaned['window_items_sold'] / test_data_cleaned['window_items_listed']\n",
    "test_data_cleaned['sales_success_ratio'] = test_data_cleaned['sales_success_ratio'].fillna(0)  # Handle NaN\n",
    "\n",
    "# Replace infinite values in the 'sales_success_ratio' column with NaN\n",
    "test_data_cleaned['sales_success_ratio'].replace([float('inf'), float('-inf')], float('nan'), inplace=True)\n",
    "# Fill NaN values with 0\n",
    "test_data_cleaned['sales_success_ratio'].fillna(0, inplace=True) \n",
    "\n",
    "test_data_cleaned['sales_success_ratio'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da6305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the new features\n",
    "test_data_cleaned[['positive_feedback_ratio', 'negative_feedback_ratio', 'sales_success_ratio']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec5815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "nominal_columns = ['country_code', 'color_primary']\n",
    "ordinal_columns = ['status', 'listing_quality_string']\n",
    "\n",
    "# Apply Label Encoding to nominal columns\n",
    "for col in nominal_columns:\n",
    "    test_data_cleaned[col] = label_encoder.fit_transform(test_data_cleaned[col])\n",
    "\n",
    "# If you also want to apply Label Encoding to the ordinal columns (if they are categorical),\n",
    "# you can do the same for those columns as well (optional, depending on the data).\n",
    "\n",
    "for col in ordinal_columns:\n",
    "    test_data_cleaned[col] = label_encoder.fit_transform(test_data_cleaned[col])\n",
    "\n",
    "# Now the data is encoded with Label Encoding for both nominal and ordinal columns.\n",
    "\n",
    "# We can also encode the 'brand' column, but if there are many categories we can only select the most important brands\n",
    "# If there is a lot of unique value, it is useful to select only the most common brands and separate the rest as 'other'.\n",
    "top_brands = test_data_cleaned['brand'].value_counts().nlargest(10).index  # The 10 most common brands\n",
    "test_data_cleaned['brand'] = test_data_cleaned['brand'].apply(lambda x: x if x in top_brands else 'other')\n",
    "test_data_cleaned = pd.get_dummies(test_data_cleaned, columns=['brand'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309632bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_cleaned[\"brand_other\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0e9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for 'status' column to numerical values\n",
    "status_mapping = {\n",
    "    'a. New with tags': 0,\n",
    "    'b. New': 1,\n",
    "    'c. Mint': 2,\n",
    "    'd. Very good': 3,\n",
    "    'e. Good': 4\n",
    "}\n",
    "\n",
    "# Map the 'status' column to 'status_mapped' column with the defined mapping\n",
    "test_data_cleaned['status_mapped'] = test_data_cleaned['status'].map(status_mapping)\n",
    "\n",
    "# Drop the 'status' column from the dataset as it is no longer needed\n",
    "test_data_cleaned = test_data_cleaned.drop(columns=['status'])\n",
    "test_data_cleaned['status_mapped'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non-numeric columns in the dataset\n",
    "non_numeric_columns = test_data_cleaned.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Apply Label Encoding to each non-numeric column in data_cleaned\n",
    "for col in non_numeric_columns:\n",
    "    test_data_cleaned[col] = label_encoder.fit_transform(test_data_cleaned[col])  # Fit and transform on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0002d41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b5d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for datetime columns\n",
    "datetime_columns = test_data_cleaned.select_dtypes(include=['datetime']).columns\n",
    "\n",
    "# Convert datetime columns to numeric values (e.g., Unix timestamp or individual components)\n",
    "for col in datetime_columns:\n",
    "    # Convert to Unix timestamp (seconds since 1970-01-01)\n",
    "    test_data_cleaned[col] = test_data_cleaned[col].astype('int64') // 10**9  # Converting to seconds\n",
    "\n",
    "    # Or, alternatively, could extract individual components like year, month, day\n",
    "    # test_data_cleaned[f'{col}_year'] = test_data_cleaned[col].dt.year\n",
    "    # test_data_cleaned[f'{col}_month'] = test_data_cleaned[col].dt.month\n",
    "    # test_data_cleaned[f'{col}_day'] = test_data_cleaned[col].dt.day\n",
    "    # test_data_cleaned = test_data_cleaned.drop(columns=[col])  # Drop original datetime column if needed\n",
    "\n",
    "# Now proceed with encoding the categorical columns as before and fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb6501",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(test_data_cleaned)  # Features should be scaled\n",
    "\n",
    "# Make predictions using the model\n",
    "test_predictions = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Add the predictions as a new column to the test dataset\n",
    "test_data_cleaned['predicted_sold'] = test_predictions\n",
    "\n",
    "# Prepare a CSV file with only 'id' and predictions\n",
    "submission = test_data_cleaned[['id', 'predicted_sold']]  # 'id' column should be present in the test dataset\n",
    "submission.rename(columns={'predicted_sold': 'sold'}, inplace=True)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Predictions for the test dataset have been successfully saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069901b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
